{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-cs-code/blob/main/sem3/DL/DL_2025_Lab6-a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyoVZ-yJQXeT"
      },
      "source": [
        "# Uczenie nienadzorowane -- wybrane metody"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0peQ_DdlQXeW"
      },
      "source": [
        "## Sieci typu koder--dekoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv-COiOiQXeX"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<!-- Potrzebne dla poprawnego wyświetlania paska postępu tqdm w VSCode https://stackoverflow.com/a/77566731 -->\n",
        "<style>\n",
        ".cell-output-ipywidget-background {\n",
        "    background-color: transparent !important;\n",
        "}\n",
        ":root {\n",
        "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
        "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
        "}\n",
        "</style>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsYye_mdQXeZ"
      },
      "outputs": [],
      "source": [
        "!uv pip -q install torchinfo\n",
        "\n",
        "# Import potrzebnych modułów i funkcji\n",
        "\n",
        "from collections import defaultdict\n",
        "from random import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.functional as F\n",
        "from torch import nn, tensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Subset\n",
        "import random\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "# Importy do wizualizacji\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7lHa_BaQXea"
      },
      "outputs": [],
      "source": [
        "def get_device():   # Obliczenia wykonamy na GPU, jeżeli jest dostępne, a na CPU w przeciwny razie\n",
        "  return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def train_unsupervised(model, train_loader, test_loader,\n",
        "                optimizer,\n",
        "                n_epochs=20, eval_every=1,\n",
        "                loss_fn=None,\n",
        "                scheduler=None,\n",
        "                device=None,\n",
        "                history=None):\n",
        "    device = device or get_device()\n",
        "\n",
        "    history = history or defaultdict(list)\n",
        "    # Przenieś model na określone urządzenie\n",
        "    model.to(device)\n",
        "\n",
        "    # Definiowanie funkcji straty\n",
        "    compute_loss = loss_fn or nn.CrossEntropyLoss()\n",
        "\n",
        "    test_loss = history['test_loss'][-1] if history['test_loss'] else 0\n",
        "\n",
        "    # Pętla treningowa\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()  # Ustaw model w tryb treningowy\n",
        "\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Iteracja po danych treningowych\n",
        "        for x_batch, _ in tqdm(train_loader):\n",
        "            # Przenieś dane na określone urządzenie\n",
        "            x_batch = x_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Wyzerowanie gradientów przed kolejną iteracją\n",
        "            out = model(x_batch)  # Faza w przód\n",
        "\n",
        "            loss = compute_loss(out, x_batch)\n",
        "\n",
        "            loss.backward()   # Faza wsteczna do obliczenia gradientów\n",
        "            optimizer.step()  # Aktualizacja parametrów modelu\n",
        "\n",
        "            total_samples += x_batch.shape[0]\n",
        "            total_loss += loss.item() * x_batch.shape[0]\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "\n",
        "        if (epoch + 1) % eval_every == 0:  # Ewaluacja na zbiorze testowym\n",
        "            model.eval()   # Ustaw model w tryb ewaluacji\n",
        "            total_loss = 0\n",
        "            total_samples = 0\n",
        "            with torch.no_grad():  # Wyłączenie obliczania gradientów\n",
        "                for x_batch, _ in tqdm(test_loader):\n",
        "                    # Przenieś dane na określone urządzenie\n",
        "                    x_batch = x_batch.to(device)\n",
        "\n",
        "                    out = model(x_batch)  # Faza w przód\n",
        "\n",
        "                    loss = compute_loss(out, x_batch)\n",
        "\n",
        "                    total_samples += x_batch.shape[0]\n",
        "                    total_loss += loss.item() * x_batch.shape[0]\n",
        "\n",
        "            test_loss = total_loss / total_samples\n",
        "\n",
        "            print(f'Epoch: {epoch}\\tTrain loss: {train_loss:.3f}'\\\n",
        "                  f'\\tTest loss: {test_loss:.3f}')\n",
        "        else:\n",
        "            print(f'Epoch: {epoch}\\tTrain loss: {train_loss:.3f}')\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtcZDf2jQXeb"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    \"\"\" Prosty model typu koder-dekoder \"\"\"\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Koder (ang. encoder)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Dekoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, input_dim),\n",
        "            nn.Sigmoid()  # Wyj. z zakresu [0, 1]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        return self.decode(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPIVH_IpQXec"
      },
      "outputs": [],
      "source": [
        "# Model przetwarza spłaszczone dane, czyli wektory, stąd konieczna jest transformacja\n",
        "flatten_transform = transforms.Lambda(lambda x: x.view(-1))\n",
        "\n",
        "# Transformacje, można również dodać odbicia itp\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts images to PyTorch tensors (values between 0 and 1)\n",
        "    flatten_transform\n",
        "])\n",
        "\n",
        "train_dataset = mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DOCtbLuQXec"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "device = get_device()\n",
        "\n",
        "# Hiperparametry\n",
        "input_dim = 28 * 28   # 784 for 28x28 images\n",
        "latent_dim = 16       # Wymiar przestrzeni ukrytej\n",
        "learning_rate = 1e-3\n",
        "\n",
        "model = Autoencoder(input_dim, latent_dim).to(device)\n",
        "print(summary(model))\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=5)\n",
        "\n",
        "train_unsupervised(model,\n",
        "                   train_loader=train_loader, test_loader=test_loader,\n",
        "                   optimizer=optimizer, scheduler=scheduler,\n",
        "                   n_epochs=7, loss_fn=nn.BCELoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWga7BNBQXed"
      },
      "outputs": [],
      "source": [
        "# Ewaluacja na zb. testowym\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    all_encoded = []\n",
        "    all_decoded = []\n",
        "    all_original = []\n",
        "    for data, _ in test_loader:\n",
        "        data = data.view(-1, input_dim).to(device)\n",
        "        encoded = model.encode(data)\n",
        "        decoded = model.decode(encoded)\n",
        "        all_encoded.append(encoded.cpu())\n",
        "        all_decoded.append(decoded.cpu())\n",
        "        all_original.append(data.cpu())\n",
        "\n",
        "    decoded_imgs = torch.cat(all_decoded)\n",
        "    original_imgs = torch.cat(all_original)\n",
        "\n",
        "decoded_imgs = decoded_imgs.numpy()\n",
        "original_imgs = original_imgs.numpy()\n",
        "\n",
        "# Wizualizacja\n",
        "n_samples = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n_samples):\n",
        "    # Oryginalne obrazy\n",
        "    ax = plt.subplot(2, n_samples, i + 1)\n",
        "    plt.imshow(original_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Oryginalne\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Rekonstrukcje\n",
        "    ax = plt.subplot(2, n_samples, i + 1 + n_samples)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Rekonstrukcje\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_zWutEXQXed"
      },
      "source": [
        "# Zadanie 1\n",
        "\n",
        "Proszę sprawdzić jak zmienia się jakość rekonstrukcji w zależności od wymiarowości reprezentacji ukrytej w autokoderze\n",
        "dla FashionMNIST (mogą być wybrane klasy).\n",
        "\n",
        "Można porównać zarówno \"surowe\" wartości f. straty, jak i ocenić różnice wizualnie."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformacje (bez zmian)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "# Załadowanie FashionMNIST\n",
        "train_fmnist = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_fmnist = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_fmnist, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_fmnist, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ICSmY68ISEAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dims = [2, 8, 32, 128]\n",
        "results = {}\n",
        "reconstructions = {}\n",
        "\n",
        "input_dim = 28 * 28\n",
        "n_epochs = 5\n",
        "\n",
        "for d in latent_dims:\n",
        "    print(f\"\\n--- Trening dla latent_dim = {d} ---\")\n",
        "    model = Autoencoder(input_dim, d).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Trening\n",
        "    history = train_unsupervised(\n",
        "        model, train_loader, test_loader,\n",
        "        optimizer, n_epochs=n_epochs, loss_fn=nn.BCELoss(), device=device\n",
        "    )\n",
        "\n",
        "    # Zapisanie wyników\n",
        "    results[d] = history['test_loss'][-1]\n",
        "\n",
        "    # Pobranie przykładowych rekonstrukcji do wizualizacji\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data, _ = next(iter(test_loader))\n",
        "        data = data.to(device)\n",
        "        recon = model(data)\n",
        "        reconstructions[d] = recon.cpu().numpy()\n",
        "        original_samples = data.cpu().numpy()"
      ],
      "metadata": {
        "id": "UUUjmV_ATxII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 5\n",
        "plt.figure(figsize=(15, 2 * (len(latent_dims) + 1)))\n",
        "\n",
        "# Oryginały\n",
        "for i in range(n_samples):\n",
        "    plt.subplot(len(latent_dims) + 1, n_samples, i + 1)\n",
        "    plt.imshow(original_samples[i].reshape(28, 28), cmap='gray')\n",
        "    if i == 0: plt.ylabel(\"Oryginał\")\n",
        "    plt.axis('off')\n",
        "\n",
        "# Rekonstrukcje dla różnych wymiarów\n",
        "for row, d in enumerate(latent_dims):\n",
        "    for i in range(n_samples):\n",
        "        plt.subplot(len(latent_dims) + 1, n_samples, (row + 1) * n_samples + i + 1)\n",
        "        plt.imshow(reconstructions[d][i].reshape(28, 28), cmap='gray')\n",
        "        if i == 0: plt.ylabel(f\"Dim: {d}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D-xx3UIrUvMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}