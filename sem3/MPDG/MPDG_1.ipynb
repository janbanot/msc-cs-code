{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAKSSmsexlaBTM8hRf3Bar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-cs-code/blob/main/sem3/MPDG/MPDG_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SG7opD33UaO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import xgboost as xgb\n",
        "\n",
        "# Ustawienie ziarna losowości dla powtarzalności wyników\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wczytanie Danych\n",
        "# Bezpośredni link do zbioru danych HCV na UCI Repository\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00571/hcvdat0.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(url)\n",
        "    print(\"Dane wczytane pomyślnie.\")\n",
        "except Exception as e:\n",
        "    print(f\"Błąd wczytywania danych: {e}\")\n",
        "\n",
        "# Usunięcie pierwszej kolumny 'Unnamed: 0'\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "wOGwaW9y3a6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opis Danych\n",
        "print(f\"\\nLiczba obserwacji: {df.shape[0]}\")\n",
        "print(f\"Liczba cech: {df.shape[1]}\")\n",
        "print(\"\\nPierwsze 5 wierszy:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInfo o typach danych i brakach:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nRozkład zmiennej celu (Category):\")\n",
        "print(df['Category'].value_counts())"
      ],
      "metadata": {
        "id": "HTU2fwdb3uFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Danych\n",
        "# Zmienna 'Sex' (f, m) -> mapujemy na 0 i 1\n",
        "df['Sex'] = df['Sex'].map({'m': 0, 'f': 1})\n",
        "\n",
        "# Zmienna celu 'Category' -> Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['Category'] = le.fit_transform(df['Category'])\n",
        "print(f\"Mapowanie klas: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
        "\n",
        "# Podział na X (cechy) i y (etykiety)\n",
        "X = df.drop(columns=['Category'])\n",
        "y = df['Category']\n",
        "\n",
        "# Podział na zbiór treningowy i testowy\n",
        "# Używamy stratify=y, ponieważ klasy mogą być nierówne (dużo dawców krwi, mało chorych)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# Obsługa brakujących danych (Missing Values)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X.columns)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X.columns)"
      ],
      "metadata": {
        "id": "zHOSxcyJ4K-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementacja Metod Zespołowych\n",
        "results = {}\n",
        "\n",
        "# METODA 1: BAGGING (Random Forest)\n",
        "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "# Definicja siatki hiperparametrów\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 15]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Najlepsze parametry RF: {grid_rf.best_params_}\")\n",
        "print(f\"Dokładność (Accuracy) RF: {acc_rf:.4f}\")\n",
        "results['Random Forest'] = acc_rf"
      ],
      "metadata": {
        "id": "yIIWNYfa49H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METODA 2: BOOSTING (XGBoost)\n",
        "# XGBoost wymaga klas od 0 do N-1, co zapewnia LabelEncoder\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Definicja siatki hiperparametrów\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb_clf, param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"Najlepsze parametry XGBoost: {grid_xgb.best_params_}\")\n",
        "print(f\"Dokładność (Accuracy) XGBoost: {acc_xgb:.4f}\")\n",
        "results['XGBoost'] = acc_xgb"
      ],
      "metadata": {
        "id": "7X01AXFo5RxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METODA 3: STACKING\n",
        "# Modele bazowe (Level-0).\n",
        "# Modele SVM czy KNN wymagają skalowania danych.\n",
        "# Używamy make_pipeline, aby skalowanie odbywało się wewnątrz Stackingu.\n",
        "\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)),\n",
        "    ('svm', make_pipeline(StandardScaler(), SVC(probability=False, random_state=RANDOM_STATE))),\n",
        "    ('knn', make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5)))\n",
        "]\n",
        "\n",
        "# Meta-model (Level-1): Regresja Logistyczna\n",
        "clf_stacking = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "clf_stacking.fit(X_train, y_train)\n",
        "y_pred_stack = clf_stacking.predict(X_test)\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "\n",
        "print(f\"Dokładność (Accuracy) Stacking: {acc_stack:.4f}\")\n",
        "results['Stacking'] = acc_stack"
      ],
      "metadata": {
        "id": "noNfunEg5lwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porównanie i Wnioski\n",
        "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
        "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "# Wizualizacja wyników\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='Model', y='Accuracy', data=results_df, palette='viridis')\n",
        "plt.title('Porównanie Dokładności Modeli')\n",
        "plt.ylim(0.8, 1.0) # Skalujemy oś Y, żeby zobaczyć różnice, bo wyniki mogą być wysokie\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Wyświetlenie szczegółowego raportu dla najlepszego modelu\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "print(f\"\\nSzczegółowy raport klasyfikacji dla najlepszego modelu ({best_model_name}):\")\n",
        "\n",
        "if best_model_name == 'Random Forest':\n",
        "    print(classification_report(y_test, y_pred_rf))\n",
        "elif best_model_name == 'XGBoost':\n",
        "    print(classification_report(y_test, y_pred_xgb))\n",
        "else:\n",
        "    print(classification_report(y_test, y_pred_stack))"
      ],
      "metadata": {
        "id": "hjXuGwlh5-P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}