{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f42c06",
   "metadata": {},
   "source": [
    "# Algorytm Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5ff5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  D\n",
      "0  1  1  0  1\n",
      "1  1  0  1  0\n",
      "2  0  1  1  1\n",
      "3  1  1  0  0\n",
      "4  0  1  1  1\n",
      "Zbiory częste:\n",
      "['A']: Wsparcie = 0.60\n",
      "['B']: Wsparcie = 0.80\n",
      "['C']: Wsparcie = 0.60\n",
      "['D']: Wsparcie = 0.60\n",
      "['A', 'B']: Wsparcie = 0.40\n",
      "['C', 'B']: Wsparcie = 0.40\n",
      "['D', 'B']: Wsparcie = 0.60\n",
      "['D', 'C']: Wsparcie = 0.40\n",
      "['D', 'C', 'B']: Wsparcie = 0.40\n",
      "\n",
      "Reguły asocjacyjne:\n",
      "A => B (Wsparcie = 0.40, Ufność = 0.67)\n",
      "C => B (Wsparcie = 0.40, Ufność = 0.67)\n",
      "D => B (Wsparcie = 0.60, Ufność = 1.00)\n",
      "B => D (Wsparcie = 0.60, Ufność = 0.75)\n",
      "D => C (Wsparcie = 0.40, Ufność = 0.67)\n",
      "C => D (Wsparcie = 0.40, Ufność = 0.67)\n",
      "D => C, B (Wsparcie = 0.40, Ufność = 0.67)\n",
      "C => D, B (Wsparcie = 0.40, Ufność = 0.67)\n",
      "D, C => B (Wsparcie = 0.40, Ufność = 1.00)\n",
      "D, B => C (Wsparcie = 0.40, Ufność = 0.67)\n",
      "C, B => D (Wsparcie = 0.40, Ufność = 1.00)\n"
     ]
    }
   ],
   "source": [
    "# 1. Implementacja ręczna algorytmu Apriori:\n",
    "\n",
    "# Dane wejściowe\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 1, 0, 1, 0],\n",
    "    'B': [1, 0, 1, 1, 1],\n",
    "    'C': [0, 1, 1, 0, 1],\n",
    "    'D': [1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Parametry algorytmu\n",
    "min_support = 0.4\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Obliczanie wsparcia dla zbiorów elementów\n",
    "def calculate_support(data, itemset):\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if all(data.iloc[i][item] == 1 for item in itemset):\n",
    "            count += 1\n",
    "    return count / len(data)\n",
    "\n",
    "# Generowanie  zbiorów częstych\n",
    "def apriori(data, min_support):\n",
    "    columns = list(data.columns)\n",
    "    frequent_itemsets = []  # Lista na zbiory częste\n",
    "\n",
    "    # Zbiory jednoelementowe\n",
    "    for col in columns:\n",
    "        support = calculate_support(data, [col])\n",
    "        if support >= min_support:\n",
    "            frequent_itemsets.append(([col], support))\n",
    "\n",
    "    # Iteracyjne generowanie większych zbiorów\n",
    "    k = 2\n",
    "    while True:\n",
    "        new_combinations = list(combinations([item[0] for item in frequent_itemsets if len(item[0]) == k - 1], k))\n",
    "        new_frequent = []\n",
    "        for combo in new_combinations:\n",
    "            merged = set().union(*combo)\n",
    "            if len(merged) == k:\n",
    "                support = calculate_support(data, merged)\n",
    "                if support >= min_support:\n",
    "                    new_frequent.append((list(merged), support))\n",
    "        if not new_frequent:\n",
    "            break\n",
    "        frequent_itemsets.extend(new_frequent)\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generowanie reguł asocjacyjnych\n",
    "def generate_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset, support in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    consequent = set(itemset) - set(antecedent)\n",
    "                    if consequent:\n",
    "                        antecedent = list(antecedent)\n",
    "                        consequent = list(consequent)\n",
    "                        antecedent_support = calculate_support(data, antecedent)\n",
    "                        confidence = support / antecedent_support\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append({\n",
    "                                'antecedent': antecedent,\n",
    "                                'consequent': consequent,\n",
    "                                'support': support,\n",
    "                                'confidence': confidence\n",
    "                            })\n",
    "    return rules\n",
    "\n",
    "# Wykonanie algorytmu\n",
    "frequent_itemsets = apriori(data, min_support)\n",
    "rules = generate_rules(frequent_itemsets, min_confidence)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "print(\"Zbiory częste:\")\n",
    "for itemset, support in frequent_itemsets:\n",
    "    print(f\"{itemset}: Wsparcie = {support:.2f}\")\n",
    "\n",
    "print(\"\\nReguły asocjacyjne:\")\n",
    "for rule in rules:\n",
    "    antecedent = ', '.join(rule['antecedent'])\n",
    "    consequent = ', '.join(rule['consequent'])\n",
    "    print(f\"{antecedent} => {consequent} (Wsparcie = {rule['support']:.2f}, Ufność = {rule['confidence']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
