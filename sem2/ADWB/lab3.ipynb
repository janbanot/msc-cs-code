{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9840d6d0",
   "metadata": {},
   "source": [
    "# Lab 3 - Jan Banot\n",
    "\n",
    "## Zadanie:\n",
    "ybierz dowolny zbiór danych transakcyjnych z publicznego repozytorium (Kaggle lub UCI Machine Learning Repository). Upewnij się, że Twój zbiór nie pokrywa się z wybranymi przez pozostałych studentów w grupie.\n",
    "\n",
    "Przeprowadź analizę reguł asocjacyjnych, obejmującą:\n",
    "- wygenerowanie zbiorów częstych i reguł asocjacyjnych dla trzech różnych par progów wsparcia i ufności,\n",
    "- porównanie wpływu zmiany progów na liczbę i jakość reguł,\n",
    "- wskazanie najciekawszych reguł oraz ich potencjalnego znaczenia w kontekście danych.\n",
    "Przygotuj sprawozdanie z wykonanych prac (skrypt Python z komentarzami, nagrany film lub raport PDF), zawierające opis wybranego zbioru, zastosowaną metodologię, wyniki analizy oraz wnioski.\n",
    "\n",
    "## Wybrany zbiór danych\n",
    "https://www.kaggle.com/datasets/aliessamali/ecommerce\n",
    "Zbiór danych został skrócony do 10tys. elementów w celach przyspieszenia obliczeń."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. WCZYTANIE I EKSPLORACJA DANYCH\n",
    "# ================================\n",
    "\n",
    "\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"\n",
    "    Wczytuje i eksploruje dane transakcyjne\n",
    "    \"\"\"\n",
    "    print(\"=== WCZYTYWANIE I EKSPLORACJA DANYCH ===\")\n",
    "\n",
    "    # Wczytanie danych\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"Kształt danych: {df.shape}\")\n",
    "    print(f\"Liczba unikalnych faktur: {df['InvoiceNo'].nunique()}\")\n",
    "    print(f\"Liczba unikalnych produktów: {df['StockCode'].nunique()}\")\n",
    "    print(f\"Liczba unikalnych klientów: {df['CustomerID'].nunique()}\")\n",
    "\n",
    "    # Sprawdzenie brakujących danych\n",
    "    print(\"\\nBrakujące dane:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd000d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. PRZYGOTOWANIE DANYCH\n",
    "# ================================\n",
    "\n",
    "\n",
    "def prepare_transaction_data(df):\n",
    "    \"\"\"\n",
    "    Przygotowuje dane do analizy reguł asocjacyjnych\n",
    "    \"\"\"\n",
    "    print(\"\\n=== PRZYGOTOWANIE DANYCH ===\")\n",
    "\n",
    "    # Usunięcie wierszy z brakującymi danymi kluczowymi\n",
    "    df_clean = df.dropna(subset=[\"InvoiceNo\", \"StockCode\", \"Description\"])\n",
    "\n",
    "    # Usunięcie transakcji anulowanych (zaczynających się od 'C')\n",
    "    df_clean = df_clean[~df_clean[\"InvoiceNo\"].astype(str).str.startswith(\"C\")]\n",
    "\n",
    "    # Usunięcie produktów o ujemnej ilości\n",
    "    df_clean = df_clean[df_clean[\"Quantity\"] > 0]\n",
    "\n",
    "    print(f\"Dane po czyszczeniu: {df_clean.shape}\")\n",
    "\n",
    "    # Grupowanie po fakturze i produktach - utworzenie macierzy transakcyjnej\n",
    "    basket = (\n",
    "        df_clean.groupby([\"InvoiceNo\", \"Description\"])[\"Quantity\"]\n",
    "        .sum()\n",
    "        .unstack()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # Konwersja na format binarny (0/1)\n",
    "    basket_sets = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    print(f\"Macierz transakcyjna: {basket_sets.shape}\")\n",
    "\n",
    "    return basket_sets, df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1351a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. ANALIZA REGUŁ ASOCJACYJNYCH\n",
    "# ================================\n",
    "\n",
    "\n",
    "def analyze_association_rules(basket_sets, min_support_values, min_confidence_values):\n",
    "    \"\"\"\n",
    "    Przeprowadza analizę reguł asocjacyjnych dla różnych progów\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for i, (min_sup, min_conf) in enumerate(\n",
    "        zip(min_support_values, min_confidence_values)\n",
    "    ):\n",
    "        print(f\"\\n=== ANALIZA {i + 1}: Support={min_sup}, Confidence={min_conf} ===\")\n",
    "\n",
    "        # Znajdowanie częstych zbiorów elementów\n",
    "        frequent_itemsets = apriori(basket_sets, min_support=min_sup, use_colnames=True)\n",
    "\n",
    "        if len(frequent_itemsets) == 0:\n",
    "            print(f\"Brak częstych zbiorów dla support={min_sup}\")\n",
    "            results[f\"config_{i + 1}\"] = {\n",
    "                \"support\": min_sup,\n",
    "                \"confidence\": min_conf,\n",
    "                \"frequent_itemsets\": pd.DataFrame(),\n",
    "                \"rules\": pd.DataFrame(),\n",
    "                \"stats\": {\"frequent_count\": 0, \"rules_count\": 0},\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        print(f\"Liczba częstych zbiorów: {len(frequent_itemsets)}\")\n",
    "\n",
    "        # Generowanie reguł asocjacyjnych\n",
    "        rules = association_rules(\n",
    "            frequent_itemsets, metric=\"confidence\", min_threshold=min_conf\n",
    "        )\n",
    "\n",
    "        print(f\"Liczba reguł: {len(rules)}\")\n",
    "\n",
    "        # Dodanie dodatkowych metryk\n",
    "        if len(rules) > 0:\n",
    "            rules = rules.round(4)\n",
    "            rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "            rules[\"consequent_len\"] = rules[\"consequents\"].apply(lambda x: len(x))\n",
    "\n",
    "        # Zapisanie wyników\n",
    "        results[f\"config_{i + 1}\"] = {\n",
    "            \"support\": min_sup,\n",
    "            \"confidence\": min_conf,\n",
    "            \"frequent_itemsets\": frequent_itemsets,\n",
    "            \"rules\": rules,\n",
    "            \"stats\": {\n",
    "                \"frequent_count\": len(frequent_itemsets),\n",
    "                \"rules_count\": len(rules),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Wyświetlenie statystyk\n",
    "        if len(rules) > 0:\n",
    "            print(f\"Średnie wsparcie: {rules['support'].mean():.4f}\")\n",
    "            print(f\"Średnia ufność: {rules['confidence'].mean():.4f}\")\n",
    "            print(f\"Średni lift: {rules['lift'].mean():.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. PORÓWNANIE WYNIKÓW\n",
    "# ================================\n",
    "\n",
    "\n",
    "def compare_results(results):\n",
    "    \"\"\"\n",
    "    Porównuje wyniki dla różnych progów\n",
    "    \"\"\"\n",
    "    print(\"\\n=== PORÓWNANIE WYNIKÓW ===\")\n",
    "\n",
    "    comparison_data = []\n",
    "    for config, data in results.items():\n",
    "        comparison_data.append(\n",
    "            {\n",
    "                \"Konfiguracja\": config,\n",
    "                \"Support\": data[\"support\"],\n",
    "                \"Confidence\": data[\"confidence\"],\n",
    "                \"Liczba częstych zbiorów\": data[\"stats\"][\"frequent_count\"],\n",
    "                \"Liczba reguł\": data[\"stats\"][\"rules_count\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. WIZUALIZACJA\n",
    "# ================================\n",
    "\n",
    "\n",
    "def create_visualizations(results, comparison_df):\n",
    "    \"\"\"\n",
    "    Tworzy wizualizacje wyników\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Porównanie liczby reguł\n",
    "    axes[0, 0].bar(comparison_df[\"Konfiguracja\"], comparison_df[\"Liczba reguł\"])\n",
    "    axes[0, 0].set_title(\"Liczba reguł dla różnych progów\")\n",
    "    axes[0, 0].set_xlabel(\"Konfiguracja\")\n",
    "    axes[0, 0].set_ylabel(\"Liczba reguł\")\n",
    "\n",
    "    # 2. Porównanie liczby częstych zbiorów\n",
    "    axes[0, 1].bar(\n",
    "        comparison_df[\"Konfiguracja\"], comparison_df[\"Liczba częstych zbiorów\"]\n",
    "    )\n",
    "    axes[0, 1].set_title(\"Liczba częstych zbiorów dla różnych progów\")\n",
    "    axes[0, 1].set_xlabel(\"Konfiguracja\")\n",
    "    axes[0, 1].set_ylabel(\"Liczba częstych zbiorów\")\n",
    "\n",
    "    # 3. Rozkład lift dla pierwszej konfiguracji z regułami\n",
    "    config_with_rules = None\n",
    "    for config, data in results.items():\n",
    "        if len(data[\"rules\"]) > 0:\n",
    "            config_with_rules = config\n",
    "            break\n",
    "\n",
    "    if config_with_rules:\n",
    "        rules = results[config_with_rules][\"rules\"]\n",
    "        axes[1, 0].hist(rules[\"lift\"], bins=20, alpha=0.7)\n",
    "        axes[1, 0].set_title(f\"Rozkład wartości Lift ({config_with_rules})\")\n",
    "        axes[1, 0].set_xlabel(\"Lift\")\n",
    "        axes[1, 0].set_ylabel(\"Częstość\")\n",
    "\n",
    "    # 4. Scatter plot support vs confidence\n",
    "    if config_with_rules:\n",
    "        scatter = axes[1, 1].scatter(\n",
    "            rules[\"support\"],\n",
    "            rules[\"confidence\"],\n",
    "            c=rules[\"lift\"],\n",
    "            cmap=\"viridis\",\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        axes[1, 1].set_title(f\"Support vs Confidence ({config_with_rules})\")\n",
    "        axes[1, 1].set_xlabel(\"Support\")\n",
    "        axes[1, 1].set_ylabel(\"Confidence\")\n",
    "        plt.colorbar(scatter, ax=axes[1, 1], label=\"Lift\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab881892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6. ANALIZA NAJCIEKAWSZYCH REGUŁ\n",
    "# ================================\n",
    "\n",
    "\n",
    "def analyze_top_rules(results):\n",
    "    \"\"\"\n",
    "    Analizuje najciekawsze reguły\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ANALIZA NAJCIEKAWSZYCH REGUŁ ===\")\n",
    "\n",
    "    for config, data in results.items():\n",
    "        rules = data[\"rules\"]\n",
    "        if len(rules) == 0:\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"\\n--- Konfiguracja: {config} (Support={data['support']}, Confidence={data['confidence']}) ---\"\n",
    "        )\n",
    "\n",
    "        # Top 5 reguł według lift\n",
    "        print(\"TOP 5 REGUŁ WEDŁUG LIFT:\")\n",
    "        top_lift = rules.nlargest(5, \"lift\")[\n",
    "            [\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]\n",
    "        ]\n",
    "        for idx, row in top_lift.iterrows():\n",
    "            antecedent = \", \".join(list(row[\"antecedents\"]))\n",
    "            consequent = \", \".join(list(row[\"consequents\"]))\n",
    "            print(f\"  {antecedent} → {consequent}\")\n",
    "            print(\n",
    "                f\"    Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}, Lift: {row['lift']:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "        # Top 5 reguł według confidence\n",
    "        print(\"TOP 5 REGUŁ WEDŁUG CONFIDENCE:\")\n",
    "        top_conf = rules.nlargest(5, \"confidence\")[\n",
    "            [\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]\n",
    "        ]\n",
    "        for idx, row in top_conf.iterrows():\n",
    "            antecedent = \", \".join(list(row[\"antecedents\"]))\n",
    "            consequent = \", \".join(list(row[\"consequents\"]))\n",
    "            print(f\"  {antecedent} → {consequent}\")\n",
    "            print(\n",
    "                f\"    Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}, Lift: {row['lift']:.4f}\\n\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 7. INTERPRETACJA BIZNESOWA\n",
    "# ================================\n",
    "\n",
    "\n",
    "def business_interpretation(results, df_clean):\n",
    "    \"\"\"\n",
    "    Interpretacja wyników w kontekście biznesowym\n",
    "    \"\"\"\n",
    "    print(\"\\n=== INTERPRETACJA BIZNESOWA ===\")\n",
    "\n",
    "    print(\"ZNACZENIE METRYK:\")\n",
    "    print(\"- Support: Jak często dany zbiór produktów występuje w transakcjach\")\n",
    "    print(\"- Confidence: Prawdopodobieństwo zakupu produktu B przy zakupie produktu A\")\n",
    "    print(\"- Lift: Czy produkty są kupowane razem częściej niż przypadkowo\")\n",
    "    print(\"  * Lift > 1: Produkty kupowane razem częściej niż przypadkowo\")\n",
    "    print(\"  * Lift = 1: Brak zależności\")\n",
    "    print(\"  * Lift < 1: Produkty kupowane razem rzadziej niż przypadkowo\")\n",
    "\n",
    "    print(\"\\nZALECANIA:\")\n",
    "    print(\"1. Reguły z wysokim lift (>1.5) wskazują na silne powiązania produktów\")\n",
    "    print(\"2. Wysokie confidence wskazuje na niezawodne predykcje zakupów\")\n",
    "    print(\"3. Odpowiedni support zapewnia statystyczną istotność reguł\")\n",
    "\n",
    "    # Analiza najpopularniejszych produktów\n",
    "    print(\"\\nNAJPOPULARNIEJSZE PRODUKTY:\")\n",
    "    top_products = df_clean[\"Description\"].value_counts().head(10)\n",
    "    print(top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/janbanot/Dev/uni/msc-cs-code/sem2/ADWB/data/e-commerce-dataset.csv\"\n",
    "\n",
    "# Wczytanie i eksploracja danych\n",
    "df = load_and_explore_data(file_path)\n",
    "\n",
    "# Przygotowanie danych\n",
    "basket_sets, df_clean = prepare_transaction_data(df)\n",
    "\n",
    "# Definicja trzech par progów (support, confidence)\n",
    "min_support_values = [0.4, 0.3, 0.2, 0.1, 0.05]\n",
    "min_confidence_values = [0.6, 0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "# Analiza reguł asocjacyjnych\n",
    "results = analyze_association_rules(basket_sets, min_support_values, min_confidence_values)\n",
    "\n",
    "# Porównanie wyników\n",
    "comparison_df = compare_results(results)\n",
    "\n",
    "# Wizualizacja\n",
    "create_visualizations(results, comparison_df)\n",
    "\n",
    "# Analiza najciekawszych reguł\n",
    "analyze_top_rules(results)\n",
    "\n",
    "# Interpretacja biznesowa\n",
    "business_interpretation(results, df_clean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-cs-code (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
