{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845d3389",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Zadanie 1 - Preprocessing danych\n",
    "## Jan Banot\n",
    "Wybrany zbiór danych: https://archive.ics.uci.edu/dataset/571/hcv+data\n",
    "\n",
    "1. Wczytanie danych i usunięcie zbędnej kolumny\n",
    "    Dane zostały wczytane z pliku CSV. Następnie usunięto kolumnę \"Unnamed: 0\", która nie była potrzebna do analizy. Utworzono również kopię oryginalnego DataFrame (df_original).\n",
    "\n",
    "2. Obsługa brakujących wartości\n",
    "    Sprawdzono, w których kolumnach występują brakujące wartości. Dla kolumn numerycznych (takich jak ALB, ALP, ALT, CHOL, PROT) brakujące wartości (NaN) zostały zastąpione średnią wartością z danej kolumny. Przeprowadzono weryfikację, aby upewnić się, że wszystkie brakujące wartości zostały uzupełnione.\n",
    "\n",
    "3. Sprawdzenie duplikatów\n",
    "    Sprawdzono, czy w zbiorze danych istnieją zduplikowane wiersze. W tym przypadku nie znaleziono duplikatów. Kod zawierał opcjonalny krok usunięcia duplikatów, gdyby zostały znalezione.\n",
    "\n",
    "4. Wykrywanie i obsługa wartości odstających\n",
    "    W kolumnach numerycznych (z wyłączeniem 'Age') zidentyfikowano wartości odstające za pomocą metody IQR (rozstęp międzykwartylowy). Wartości poniżej Q1 - 1.5 * IQR oraz powyżej Q3 + 1.5 * IQR uznano za outliery. Wykryte wartości odstające zostały zastąpione wartościami granicznymi (dolną lub górną granicą wyznaczoną przez IQR), aby zmniejszyć ich wpływ na model.\n",
    "\n",
    "5. Normalizacja danych\n",
    "    Kolumny numeryczne (z wyłączeniem 'Age') zostały znormalizowane za pomocą skalowania Min-Max (MinMaxScaler). Ta technika przeskalowuje wartości do zakresu [0, 1].\n",
    "\n",
    "6. Dyskretyzacja danych\n",
    "    Kolumna 'Age' została poddana dyskretyzacji za pomocą KBinsDiscretizer. Wartości wieku zostały podzielone na 10 przedziałów (binów) o równej szerokości ('uniform'), a następnie zakodowane jako liczby porządkowe (0-9). Utworzono nową kolumnę 'Age_Category'.\n",
    "\n",
    "7. Kodowanie zmiennych kategorycznych\n",
    "    Zmienna kategoryczna 'Category' została zakodowana za pomocą techniki one-hot encoding (przy użyciu pd.get_dummies). Usunięto pierwszą kategorię (drop_first=True), aby uniknąć współliniowości. W wyniku tego powstały nowe binarne kolumny reprezentujące poszczególne kategorie (np. 'Category_0s=suspect Blood Donor', 'Category_1=Hepatitis' itd.).\n",
    "\n",
    "8. Podział zbioru danych\n",
    "    Przygotowany zbiór danych został podzielony na zbiór treningowy i testowy. Kolumny wynikowe z kodowania one-hot zostały zdefiniowane jako zmienne docelowe (y), a pozostałe kolumny jako cechy (X). Podziału dokonano w stosunku 60% danych treningowych i 40% danych testowych (test_size=0.4), z ustalonym random_state dla powtarzalności wyników.\n",
    "\n",
    "9. Wizualizacja danych\n",
    "    Przeprowadzono wizualizację danych przed i po preprocessingu, aby zilustrować wpływ wykonanych kroków na dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04598d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 1 - wczytanie danych z pliku CSV oraz usunięcie niepotrzebnej kolumny \"Unnamed: 0\"\n",
    "df = pd.read_csv(\"/Users/janbanot/Dev/studia/msc-cs-code/sem2/ADWB/data/hcvdat0.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f99ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 2 - Obsługa brakujących wartości. Dla kolumn numerycznych, brakujące wartości zastępujemy średnią wartościa z tej kolumny\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Brakujące wartości: \\n{missing_values}\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "# Weryfikacja, czy brakujące wartości zostały usunięte\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Brakujące wartości: \\n{missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e52dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 3 - Sprawdzenie duplikatów\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Liczba duplikatów: {duplicates}\")\n",
    "\n",
    "# Opcjonalnie: usunięcie duplikatów\n",
    "if duplicates > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplikaty zostały usunięte.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52bb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 4 - Wykrywanie outlierów w kolumnach numerycznych\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "numeric_cols = numeric_cols.drop(\"Age\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)  # Pierwszy kwartyl\n",
    "    Q3 = df[col].quantile(0.75)  # Trzeci kwartyl\n",
    "    IQR = Q3 - Q1  # Rozstęp międzykwartylowy\n",
    "\n",
    "    # Obliczanie granic dla outlierów\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Wykrywanie outlierów\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f\"Kolumna: {col}\")\n",
    "    print(f\"Liczba outlierów: {len(outliers)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Zastępowanie outlierów wartościami granicznymi\n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a30ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 5 - Normalizacja danych\n",
    "# Zastosowanie Min-Max Scaling do kolumn numerycznych\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "# Wykluczamy kolumnę \"Age\" z normalizacji\n",
    "numeric_cols = numeric_cols.drop(\"Age\")\n",
    "\n",
    "# Zastosowanie Min-Max Scaling do kolumn numerycznych\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 6 - Dyskretyzacja danych za pomocą KBinsDiscretizer\n",
    "\n",
    "#\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "df['Age_Category'] = kbins.fit_transform(df[['Age']]).astype(int)  # Dyskretyzacja kolumny \"Age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 7 - Kodowanie zmiennych kategorycznych za pomocą one-hot encoding\n",
    "# Wybór kolumn kategorycznych\n",
    "categorical_cols = ['Category']\n",
    "\n",
    "# Kodowanie zmiennych kategorycznych\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 8 - Podział zbioru danych na zbiór treningowy i testowy\n",
    "\n",
    "# Usunięcie kolumn kategorycznych, które nie są potrzebne\n",
    "target_cols = ['Category_0s=suspect Blood Donor', 'Category_1=Hepatitis', 'Category_2=Fibrosis', 'Category_3=Cirrhosis']\n",
    "df_train = df.copy()\n",
    "df_train.head()\n",
    "\n",
    "X = df_train.drop(columns=target_cols)  # Kolumny cech\n",
    "X = X.drop(columns=[\"Age_Category\"])\n",
    "y = df_train[target_cols]  # Kolumny docelowe\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Weryfikacja rozmiarów zbiorów\n",
    "print(f\"Rozmiar zbioru treningowego: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Rozmiar zbioru testowego: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 9 - Wizualizacja danych\n",
    "\n",
    "# Histogram dla zmiennej \"Age\" w df_original\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_original['Age'], kde=True, bins=20, color='purple')\n",
    "plt.title('Histogram zmiennej \"Age\" w oryginalnym zbiorze danych')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Liczba wystąpień')\n",
    "plt.show()\n",
    "\n",
    "# Wykres słupkowy dla zmiennej \"Category\" w df_original\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts = df_original['Category'].value_counts()\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
    "plt.title('Rozkład zmiennej \"Category\" w oryginalnym zbiorze danych')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Liczba wystąpień')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Analiza rozkładu zmiennej \"ALP\" przed i po preprocessingu\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram dla df_original (przed preprocessingu)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_original['ALP'], kde=True, bins=20, color='blue')\n",
    "plt.title('Rozkład zmiennej \"ALP\" przed preprocessingu')\n",
    "plt.xlabel('ALP')\n",
    "plt.ylabel('Liczba wystąpień')\n",
    "\n",
    "# Histogram dla df (po preprocessingu)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['ALP'], kde=True, bins=20, color='green')\n",
    "plt.title('Rozkład zmiennej \"ALP\" po preprocessingu')\n",
    "plt.xlabel('ALP')\n",
    "plt.ylabel('Liczba wystąpień')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot dla df_original (przed preprocessingu)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=df_original['ALP'], color='blue')\n",
    "plt.title('Boxplot zmiennej \"ALP\" przed preprocessingu')\n",
    "plt.ylabel('ALP')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot dla df (po preprocessingu)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=df['ALP'], color='green')\n",
    "plt.title('Boxplot zmiennej \"ALP\" po preprocessingu')\n",
    "plt.ylabel('ALP')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
